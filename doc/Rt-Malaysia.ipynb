{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing $R_t$ (effective reproduction number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "## Back projection from confirmed cases to onset\n",
    "In Malaysia, as far as the author concerns, only confirmed cases is available and no onset data is provided officially. Also, no distinction between domestic and import cases.\n",
    "First, we backproject the confirmed cases to onset estimation. A quick way is to convolute the confirmed cases with delay distribution from confirmed to onset cases. Let $C(t)$, $O(t)$, and $d_{CO}(t)$ be confirmed, onset cases and the delay distribution function. Then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "O(t)=\\int_{0}^{t}ds\\,C(s)d_{CO}(t-s)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we use another way to consider uncertainty of estimation by Becker <cite data-cite=\"becker1997\">[2]</cite>. In this method, confirmed cases $C(t)$ is considered as a realization of stochasitc variable of which expectation is $\\mu_t$. $C(t)$ is decomposed into $n_{ts}$ being the number of onset at $s$, confirmed at $t$. Similarly, $O(s)$ is a realization of stochastic variable with its expectation $\\theta_s$. Then the expecation of $n_{ts}$ is $\\theta_s d_{OC}(t-s)$ and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mu_t=\\int_{0}^{t}ds\\,\\theta_s d_{OC}(t-s)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we use Weibull distribution of $a=1.741, b=8.573$ for $d_{OC}(t)$ <cite data-cite=\"NishiuraGitHub\">[1]</cite>.\n",
    "Suppose that a process for $n_{ts}$ obeys Poisson distribution, maximum likelihood function is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L(\\{\\mu_t\\},\\{\\theta_s\\};\\{n_{ts}\\})=\\prod^{\\tau}_{t=0} \\prod^{t}_{s=0} \\frac{\\exp\\left(-\\theta_s d_{OC}(t-s)\\right)}{n_{ts}!} (\\theta_s d_{OC}(t-s))^{n_{ts}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying logarithm,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\ell(\\{\\mu_t\\},\\{\\theta_s\\};\\{n_{ts}\\})=\\ln{L}=\\sum^{\\tau}_{t=0} \\sum^{t}_{s=0}\\left[-\\theta_s d_{OC}(t-s))-\\ln{n_{ts}!} +n_{ts}\\ln{\\theta_s}+n_{ts}\\ln{d_{OC}(t-s)}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMS algorithm in general\n",
    "We briefly look at EMS algorithm. We have observables $O(t)$ and unobservables $n_{ts}$ with unknown parameters $\\theta_s$. Maximum likelihood is $L(\\{\\theta_s\\}|\\{O(t)\\})=p(\\{O(t)\\}|\\{\\theta_s\\})$. The log ML(maximum likelihood) is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\ell(\\{\\theta_s\\}|\\{O(t)\\}) = \\ln p(\\{O(t)\\}|\\{\\theta_s\\})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing a functional $\\mathcal{L}(\\{q(\\{n_{ts}\\})\\}, \\{\\theta_s\\})$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathcal{L}(\\{q(\\{n_{ts}\\})\\}, \\{\\theta_s\\}) = \\sum_{\\{n_{ts}\\}} {q(\\{n_{ts}\\}) \\ln \\frac{p(\\{O(t)\\},\\{n_{ts}\\}|\\{\\theta_s\\})}{q(\\{n_{ts}\\})}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Kullback-Leibler divervence,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "KL(\\{q(\\{n_{ts}\\})\\}| \\{p\\}) = -\\sum_{\\{n_{ts}\\}} {q(\\{n_{ts}\\}) \\ln \\frac{p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta_s\\})}{q(\\{n_{ts}\\})}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $KL$ is always non-negative because of Gibbs inequality derived from convexity of a logarithm function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "KL(\\{q(\\{n_{ts}\\})\\}| \\{p\\}) \\ge -\\ln \\sum_{\\{n_{ts}\\}} {q(\\{n_{ts}\\})\\frac{p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta_s\\})}{q(\\{n_{ts}\\})}}=-\\ln \\sum_{\\{n_{ts}\\}} p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta_s\\})=0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the equality holds only when $q(\\{n_{ts}\\})=p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta_s\\})$. Or it can be also derived with Lagrange multiplier. Because of $p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta_s\\})=\\frac{p(\\{n_{ts}\\},\\{O(t)\\}|\\{\\theta_s\\})}{p(\\{O(t)\\}|\\{\\theta_s\\})}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "KL(\\{q(\\{n_{ts}\\})\\}| \\{p\\}) = -\\mathcal{L}+\\sum_{\\{n_{ts}\\}} {q(\\{n_{ts}\\}) \\ln p(\\{O(t)\\}|\\{O(t)\\},\\{\\theta_s\\})}=-\\mathcal{L}+\\ell\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\ell(\\{\\theta_s\\}|\\{O(t)\\}) \\ge \\mathcal{L}(\\{q(\\{n_{ts}\\})\\}, \\{\\theta_s\\})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the equality holds only when $q(\\{n_{ts}\\})=p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta_s\\})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E step\n",
    "First, set initial $\\{\\theta^{j}_s\\}$$(j=0)$. General procedure is to maximize $\\mathcal{L}(\\{q(\\{n_{ts}\\})\\}, \\{\\theta^{j}_s\\})$ via changing a functional $q(\\{n_{ts}\\})$. When it is achieved, it means that a resultant $q(\\{n_{ts}\\})$ holds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "q(\\{n_{ts}\\}) = p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and that $\\mathcal{L}(\\{q(\\{n_{ts}\\})\\}, \\{\\theta^{j}_s\\})=\\ell(\\{\\theta^{j}_s\\}|\\{O(t)\\})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M step\n",
    "Substitute $q(\\{n_{ts}\\}) = p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})$ into $\\mathcal{L}(\\{q(\\{n_{ts}\\})\\}, \\{\\theta_s\\})$, then maximize $\\mathcal{L}(\\{p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})\\}, \\{\\theta_s\\})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathcal{L}(\\{p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})\\}, \\{\\theta_s\\}) = \\sum_{\\{n_{ts}\\}} {p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\}) \\ln \\frac{p(\\{O(t)\\},\\{n_{ts}\\}|\\{\\theta_s\\})}{p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})}}\\\\=\\sum_{\\{n_{ts}\\}} {p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\}) \\ln p(\\{O(t)\\},\\{n_{ts}\\}|\\{\\theta_s\\})}+const\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where const does not include $\\{\\theta_s\\}$. Therefore, it is enough to maximize only the first term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Q(\\{\\theta_s\\}|\\{\\theta^j_s\\})=\\sum_{\\{n_{ts}\\}} {p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\}) \\ln p(\\{O(t)\\},\\{n_{ts}\\}|\\{\\theta_s\\})}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and obtain a next optimum parameters $\\{\\theta^{j+1}_s\\}$. It increases $Q$ and $\\mathcal{L}$, but does not guarantee $\\ell=\\mathcal{L}$. So, we go back to E step again to find $q$ to achieve $\\ell=\\mathcal{L}$ after finishing the following S step if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S step\n",
    "Generally speaking, a set of parameters $\\{\\theta^{j+1}_s\\}$ might not be smooth on $s$ even though it should be. Typical example is that $\\{\\theta^{j+1}_s\\}$ is a time series. In such a case, we smooth $\\{\\theta^{j+1}_s\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Theta^{j+1}_s = \\sum^{\\infty}_{t=-\\infty}{w_{s-t} \\theta^{j+1}_t }\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $w_{s-t}$ is a weight function and often a binomial coefficient $_k{C_{s-t-\\frac{k}{2}}}\\,/\\,2^k$. k has to be an even integer. Then we replace $\\theta^{j+1}$ with $\\Theta^{j+1}$ and go back to E step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMS algorithm for back projection of confirmed cases\n",
    "In our case,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\ln p(\\{O(t)\\},\\{n_{ts}\\}|\\{\\theta_s\\})=\\sum^{\\tau}_{t=0} \\sum^{t}_{s=0}[-\\theta_s d_{OC}(t-s))-\\ln{n_{ts}!} +n_{ts}\\ln{\\theta_s}+n_{ts}\\ln{d_{OC}(t-s)}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E step for back projection\n",
    "we know optimum $p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\}) =\\prod^{\\tau}_{t=0} 1_{\\sum^{t}_{s=0}{n_{ts}}=O(t)}\\prod^{t}_{s=0} \\frac{\\exp(-\\theta^j_s d_{OC}(t-s))}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M step for back projection\n",
    "Using $p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\})$ from E step,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Q(\\{\\theta_s\\}|\\{\\theta^j_s\\})=\\sum_{\\{n_{ts}\\}} {p(\\{n_{ts}\\}|\\{O(t)\\},\\{\\theta^{j}_s\\}) \\ln p(\\{O(t)\\},\\{n_{ts}\\}|\\{\\theta_s\\})}\\\\\n",
    "=\\sum^{\\tau}_{t=0} \\sum^{t}_{s=0}[-\\theta_s d_{OC}(t-s)) +\\langle n_{ts}\\rangle_{p(n|O,\\theta^j)}\\ln{\\theta_s}]\\\\ + \\sum^{\\tau}_{t=0} \\sum^{t}_{s=0}[-\\langle \\ln{n_{ts}!}\\rangle_{p(n|O,\\theta^j)} +\\langle n_{ts}\\rangle_{p(n|O,\\theta^j)}\\ln{d_{OC}(t-s)}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the final line does not depend on $\\theta$, but only $\\theta^j$, so can be treated as constant. Also, from $\\sum^{t}_{s=0}{n_{ts}}=n_{t0}+...+n_{tt}=O(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\langle n_{t\\tau}\\rangle_{p(n|O,\\theta^j)}=\\frac{\\sum_{n_{t0}+...+n_{tt}=O(t)}{\\prod^{t}_{s=0} \\frac{\\exp(-\\theta^j_s d_{OC}(t-s))}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}n_{t\\tau}}}\n",
    "{\\sum_{n_{t0}+...+n_{tt}=O(t)}{\\prod^{t}_{s=0} \\frac{\\exp(-\\theta^j_s d_{OC}(t-s))}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}}}\\\\\n",
    "=\\frac{\\sum_{n_{t0}+...+n_{tt}=O(t)}{\\prod^{t}_{s=0} \\frac{1}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}n_{t\\tau}}}\n",
    "{\\sum_{n_{t0}+...+n_{tt}=O(t)}{\\prod^{t}_{s=0} \\frac{1}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}}}\n",
    "=\\theta^j_\\tau d_{OC}(t-\\tau)\\frac{\\sum_{m_{t0}+...+m_{t\\tau}+...+m_{tt}=O(t)-1}{\\prod^{t}_{s=0} \\frac{1}{m_{ts}!} (\\theta^j_s d_{OC}(t-s))^{m_{ts}}}}\n",
    "{\\sum_{n_{t0}+...+n_{tt}=O(t)}{\\prod^{t}_{s=0} \\frac{1}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}}}\\\\\n",
    "=\\theta^j_\\tau d_{OC}(t-\\tau)\\frac{O(t)!\\sum_{m_{t0}+...+m_{t\\tau}+...+m_{tt}=O(t)-1}{(O(t)-1)!\\prod^{t}_{s=0} \\frac{1}{m_{ts}!} (\\theta^j_s d_{OC}(t-s))^{m_{ts}}}}\n",
    "{(O(t)-1)!\\sum_{n_{t0}+...+n_{tt}=O(t)}{O(t)!\\prod^{t}_{s=0} \\frac{1}{n_{ts}!} (\\theta^j_s d_{OC}(t-s))^{n_{ts}}}}\\\\\n",
    "=\\theta^j_\\tau d_{OC}(t-\\tau)\\frac{O(t)! [\\sum^t_{s=0}{\\theta^j_s d_{OC}(t-s)}]^{O(t)-1} }\n",
    "{(O(t)-1)![\\sum^t_{s=0}{\\theta^j_s d_{OC}(t-s)}]^{O(t)}}\n",
    "=O(t)\\frac{\\theta^j_\\tau d_{OC}(t-\\tau)}{\\sum^t_{s=0}{\\theta^j_s d_{OC}(t-s)}}=O(t)\\frac{\\theta^j_\\tau d_{OC}(t-\\tau)}{\\mu_t}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $m_{ts}=n_{ts}-\\delta_{s\\tau}$ and multinomial theorem is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Q(\\{\\theta_s\\}|\\{\\theta^j_s\\})=\\sum^{\\tau}_{t=0} \\sum^{t}_{s=0}\\left[-\\theta_s d_{OC}(t-s)) +O(t)\\frac{\\theta^j_s d_{OC}(t-s)}{\\mu_t}\\ln{\\theta_s}\\right] + const.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing $Q$ with respect to $\\theta_s$, because of $\\sum^{\\tau}_{t=0} \\sum^{t}_{s=0}=\\sum^{\\tau}_{s=0} \\sum^{\\tau}_{t=s}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "0=\\frac{\\partial Q(\\{\\theta_s\\}|\\{\\theta^j_s\\})}{\\partial \\theta_s}=\\sum^{\\tau}_{t=s}\\left[-d_{OC}(t-s)) +O(t)\\frac{\\theta^j_s d_{OC}(t-s)}{\\mu_t\\theta_s}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\theta_s=\\frac{\\sum^{\\tau}_{t=s}O(t)\\frac{\\theta^j_s d_{OC}(t-s)}{\\mu_t}}{\\sum^{\\tau}_{t=s}d_{OC}(t-s))}=\\frac{1}{F_{\\tau-s}}\\sum^{\\tau}_{t=s}O(t)\\frac{\\theta^j_s d_{OC}(t-s)}{\\mu_t}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $F_{\\tau-s}=\\sum^{\\tau}_{t=s}d_{OC}(t-s))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S step for back projection\n",
    "Because $\\theta_{j+1}$ is a convolution with a window function $d_{OC}$, we want $\\theta_{j+1}$ to change with characteristic length of $d_{OC}$, defined as $T^*$. This length is the time of the peak of a delay function $d_{OC}$.\n",
    "On the other hand, the standard deviation of the weight function $\\frac{_k{C_{p-k/2}}}{2^k}$ is $\\frac{\\sqrt{k}}{2}$, but multipy it by $2$ because the convolution is taken on both sides, thus $\\sqrt{k}$ effectively. Equating the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "k=T^{*2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right censorship for onset data\n",
    "Because of the delay between onset and confirmed dates, implied onset data on recent dates is missing some portion of data of future cases. Suppose today is 10 Aug 2020, onset data on 9 Aug 2020 should include 11 Aug 2020, 12 Aug 2020, ..., but data for those days is unknown. Other literatures divides the onset data by a delay function. Here, I just extrapolate the number of today's confirmed cases to 20 future dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back projection and right censorship from onset to infection data\n",
    "We repeat the above back projection and right censorship methods. Instead of delay distribution of onset and confirmed cases, now a delay distribution of infection and onset cases $d_{IO}$. We use a lognormal distribution with log mean = 1.519 and log std = 0.615 <cite data-cite=\"NishiuraGitHub\">[1]</cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of $R_t$\n",
    "We have estimated infection cases $I(t)$. Suppose the serial interval is $\\tau$. We assume that serial interal equals to generation time. By definition of $R_t$, $I(t-\\tau)$ is expected to grow after one generation to $R_t I(t-\\tau)$. If the serial interval has distribution $g(\\tau)$, expected infection cases are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "R_t \\sum^t_{\\tau=1}{I(t-\\tau)g(\\tau)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we assume Poisson distribution <cite data-cite=\"NishiuraGitHub\">[1]</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(I(t)|R_t)=\\exp\\left(-R_t \\sum^t_{\\tau=1}{I(t-\\tau)g(\\tau)}\\right)\\frac{1}{(I(t))!} (I(t))^{R_t \\sum^t_{\\tau=1}{I(t-\\tau)g(\\tau)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know imported and domestic cases separately, $I_{total}(t-\\tau)$ contributes $I_{domestic}(t)$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(I_{domestic}(t)|R_t)=\\exp\\left(-R_t \\sum^t_{\\tau=1}{I_{total}(t-\\tau)g(\\tau)}\\right)\\frac{1}{(I_{domestic}(t))!} (I_{domestic}(t))^{R_t \\sum^t_{\\tau=1}{I_{total}(t-\\tau)g(\\tau)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we only know the total cases, so we do not use this formula anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to maximize is probability of $R_t$ given a series of infection cases $\\{I(t), s\\le t\\}$ <cite data-cite=\"KSysGitHub\">[3]</cite><cite data-cite=\"KSysMCMCGitHub\">[4]</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(R_t|\\{I(s),s\\le t\\})=\\frac{P(I(t)|R_t, \\{I(s),s\\le t-1\\})}{P(I(t)|\\{I(s),s\\le t-1\\})}P(R_t|\\{I(s),s\\le t-1\\})\\\\\n",
    "=\\frac{P(I(t)|R_t, \\{I(s),s\\le t-1\\})}{P(I(t))}\\sum_{R_{t-1}}P(R_t|R_{t-1})P(R_{t-1}|\\{I(s),s\\le t-1\\})\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate the expansion to get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(R_t|\\{I(s),s\\le t\\})=\\frac{P(I(t)|R_t, \\{I(s),s\\le t-1\\})}{P(I(t))}\\\\\n",
    "\\times\\sum_{R_{t-1}}P(R_t|R_{t-1})\\frac{P(I(t-1)|R_{t-1}, \\{I(s),s\\le t-2\\})}{P(I(t-1))}\\\\\n",
    "\\times\\sum_{R_{t-2}}P(R_{t-1}|R_{t-2})\\frac{P(I(t-2)|R_{t-2}, \\{I(s),s\\le t-3\\})}{P(I(t-2))}\\\\\n",
    "...\\\\\n",
    "\\times\\sum_{R_{0}}P(R_1|R_{0})P(R_{0}|I(0))\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ignore $P(I(s))$ because it does not affect $R_s$, and assume $P(R_s|R_{s-1})$ a normal distribution with mean $R_{s-1}$ and std $\\sigma$ and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(I(s)|R_s, \\{I(\\tau),\\tau\\le s-1\\})=\\exp\\left(-R_s \\sum^s_{\\tau=1}{I(s-\\tau)g(\\tau)}\\right)\\frac{1}{(I(s))!} (I(s))^{R_s \\sum^s_{\\tau=1}{I(s-\\tau)g(\\tau)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely value of $R_t$ and its confidence intervals can be obtained from the likelihood function $P(R_s|\\{I(\\tau),\\tau\\le t\\})$.\n",
    "We determine $\\sigma$ to minimize the total of likelihood function over time and states in a country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty from right censorship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that confirmed cases beyond today is the same as the today's number. Obviously this is not the case, but changes stochastically. This stochasticity should be accounted in the probability distribution $P(R_t|\\{I(s),s\\le t\\})$ hence confidence intervals.\n",
    "\n",
    "Now, we take this uncertainty into account by bumping future confirmed cases. Time horizon is extened by the number of days $L$ of which a cumulative delay function between confirmed and infection cases makes up 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum^L_{t=1} d_{IC}(t) = 0.99\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the delay function $d_{IC}$ between confirmed and infection cases is just a convolution between $d_{OC}$ and $d_{IO}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "d_{IC}(t) = \\sum^t_{s=1} d_{OC}(s) d_{IO}(t-s)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose today is $T$. If we bump $\\Delta C(T+\\Delta t)\\,(1\\le \\Delta t\\le L)$, impact on $I(s)\\,(s\\le T)$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Delta I(s) = \\Delta C(T+\\Delta t) d_{IC}(T+\\Delta t-s)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding to this bump, the most likely value of $R_t\\,(T-L\\le t\\le T)$ changes by $\\Delta R_t$. Thus we compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\Delta R_t}{\\Delta C(t+\\Delta t)}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we compute autocovariance of change of confirmed cases with lag $\\Delta t$, $\\Delta C_{\\Delta t}(t)=C(t+\\Delta t)-C(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Cov(\\Delta C_{\\Delta t}, \\Delta C_{\\Delta s}) = \\langle \\Delta C_{\\Delta t}(t) \\Delta C_{\\Delta s}(t) \\rangle_{sample}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\langle ... \\rangle_{sample}$ means unbiased average over time series. Then, change of $R_t\\,(t\\ge T)$ can be estimated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "StdDev(\\Delta R_t)_{\\Delta t=t-T}=\\sqrt{\\sum^{L}_{\\Delta \\tau=1} \\sum^{L}_{\\Delta s=1} \\frac{\\Delta R_t}{\\Delta C(t+\\Delta\\tau)} \\frac{\\Delta R_t}{\\Delta C(t+\\Delta s)} Cov(\\Delta C_{\\Delta \\tau}, \\Delta C_{\\Delta s})}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability density is approximated with a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P_{R_t}(r)=\\frac{1}{\\sqrt{2\\pi}StdDev(\\Delta R_t)_{\\Delta t=t-T}}\\exp\\left[ -\\frac{(r-R_t)^2}{2StdDev^2(\\Delta R_t)_{\\Delta t=t-T}}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be normalized in $[0,\\infty]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\tilde{P}_{R_t}(r)=\\frac{P_{R_t}(r)}{\\int^{\\infty}_0\\,d\\rho\\,P_{R_t}(\\rho)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then $P(R_t|\\{I(s),s\\le t\\})$ is replaced with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\int^{\\infty}_{0}dr\\,\\tilde{P}_{R_t}(r)P(r|\\{I(s),s\\le t\\})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, obtain the most likely value of $R_t$ and its confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{thebibliography}{1}\n",
    "\\bibitem{NishiuraGitHub} \n",
    "Calculating Rt using Maximum likelihood estimation\n",
    "H. Nushiura, et. al., 2020\\\\\n",
    "\\url{https://github.com/contactmodel/COVID19-Japan-Reff/blob/master/scripts/B.%20Calculating%20Rt%20using%20Maximum%20likelihood%20estimation.ipynb}\n",
    "\n",
    "\\bibitem{becker1997} \n",
    "Uses of the EM algorithm in the analysis of data\n",
    "on HIV/AIDS and other infectious diseases, N. G. Becker, Statistical Methods in Medical Research 1997, 6\\\\\n",
    "\\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.938.1599&rep=rep1&type=pdf}\n",
    "\n",
    "\\bibitem{KSysGitHub} \n",
    "Estimating COVID-19's $R_t$ in Real-Time\n",
    "K. Systrom, 2020\\\\\n",
    "\\url{https://github.com/k-sys/covid-19/blob/master/Realtime%20R0.ipynb}\n",
    "\n",
    "\\bibitem{KSysMCMCGitHub} \n",
    "Estimating COVID-19's $R_t$ in Real-Time with PYMC3\n",
    "K. Systrom, 2020\\\\\n",
    "\\url{https://github.com/k-sys/covid-19/blob/master/Realtime%20Rt%20mcmc.ipynb}\n",
    "\n",
    "\\end{thebibliography}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
